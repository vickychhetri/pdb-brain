import os
import tempfile
from fastapi import FastAPI, UploadFile, File
from qdrant_client import QdrantClient
from qdrant_client.http import models as qmodels
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_qdrant import QdrantVectorStore
from docling.document_converter import DocumentConverter
from langchain_ollama import OllamaEmbeddings

# -------------------
# Init services
# -------------------
app = FastAPI()

qdrant = QdrantClient(url="http://qdrant:6333")
COLLECTION_NAME = "documents"

# Embeddings from Ollama (Mistral)
embeddings = OllamaEmbeddings(model="mistral", base_url="http://ollama:11434")

# Set vector size manually (depends on embedding model â†’ Mistral embeddings are 4096-dim)
VECTOR_SIZE = 4096

# Ensure collection exists
collections = [c.name for c in qdrant.get_collections().collections]
if COLLECTION_NAME not in collections:
    qdrant.create_collection(
        collection_name=COLLECTION_NAME,
        vectors_config=qmodels.VectorParams(
            size=VECTOR_SIZE,
            distance=qmodels.Distance.COSINE
        ),
    )

# -------------------
# API Routes
# -------------------

@app.post("/ingest")
async def ingest_document(file: UploadFile = File(...)):
    """Ingest a document into Qdrant after parsing with Docling."""
    # Save uploaded file temporarily
    with tempfile.NamedTemporaryFile(delete=False) as tmp:
        tmp.write(await file.read())
        tmp_path = tmp.name

    # Convert with Docling
    converter = DocumentConverter()
    result = converter.convert(tmp_path)
    text = result.document.export_to_markdown()

    # Split text into chunks
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    chunks = splitter.split_text(text)

    # Store in Qdrant
    # vector_store = QdrantVectorStore.from_texts(
    #     texts=chunks,
    #     embedding=embeddings,
    #     client=qdrant,
    #     collection_name=COLLECTION_NAME,
    # )
    vector_store = QdrantVectorStore(
    client=qdrant,
    collection_name=COLLECTION_NAME,
    embedding=embeddings,
    )
    vector_store.add_texts(chunks)


    return {"status": "success", "chunks_ingested": len(chunks)}

@app.get("/query")
async def query_document(q: str):
    """Query ingested documents."""
    vector_store = QdrantVectorStore(
        client=qdrant, collection_name=COLLECTION_NAME, embedding=embeddings
    )
    retriever = vector_store.as_retriever(search_type="similarity", search_kwargs={"k": 5})

    # Retrieve relevant docs
    docs = retriever.get_relevant_documents(q)

    # Format response
    return {
        "query": q,
        "results": [d.page_content for d in docs]
    }
